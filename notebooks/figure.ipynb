{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(\n",
    "    style=\"ticks\", rc={\"axes.formatter.limits\": (-4, 5)}, font_scale=1.4\n",
    ")  # 'font.weight': 'bold'\n",
    "figsize = (4.8 * 1 / 0.618, 4.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Dataset\": [\n",
    "        \"Walmart-Amazon\",\n",
    "        \"Abt-Buy\",\n",
    "        \"Amazon-Google\",\n",
    "        \"DBLP-Scholar\",\n",
    "        \"DBLP-ACM\",\n",
    "        \"IMDB-TMDB\",\n",
    "        \"IMDB-TVDB\",\n",
    "        \"TMDB-TVDB\",\n",
    "    ],\n",
    "    \"Matching/F1\": [56.03, 44.36, 78.93, 71.89, 72.05, 61.11, 77.05, 50.77],\n",
    "    \"Matching/P\": [40.41, 35.54, 65.78, 64.63, 95.08, 68.75, 65.28, 35.62],\n",
    "    \"Matching/R\": [91.33, 59.00, 98.67, 81.00, 58.00, 55.00, 94.00, 88.33],\n",
    "    \"Matching\\n(6-shot)/F1\": [77.59, 60.21, 73.13, 52.88, 84.05, 71.45, 71.21, 69.37],\n",
    "    \"Matching\\n(6-shot)/P\": [66.91, 45.75, 57.86, 36.89, 73.38, 58.00, 57.32, 54.97],\n",
    "    \"Matching\\n(6-shot)/R\": [92.33, 88.00, 99.33, 93.33, 98.33, 93.00, 94.00, 94.00],\n",
    "    \"Comparing/F1\": [79.45, 51.61, 76.61, 65.59, 62.92, 46.12, 87.27, 65.34],\n",
    "    \"Comparing/P\": [81.69, 65.31, 85.60, 82.74, 96.55, 84.82, 88.93, 71.26],\n",
    "    \"Comparing/R\": [77.33, 42.67, 69.33, 54.33, 46.67, 31.67, 85.67, 60.33],\n",
    "    \"Selecting/F1\": [80.31, 63.65, 88.62, 80.61, 92.43, 83.36, 83.66, 80.18],\n",
    "    \"Selecting/P\": [74.08, 58.13, 81.34, 73.89, 89.41, 84.07, 77.18, 72.95],\n",
    "    \"Selecting/R\": [87.67, 70.33, 97.33, 88.67, 95.67, 82.67, 91.33, 89.00],\n",
    "    \"CᴏᴍEM/F1\": [87.62, 69.63, 90.85, 84.68, 96.74, 84.16, 84.82, 86.37],\n",
    "    \"CᴏᴍEM/P\": [85.67, 66.57, 86.23, 80.48, 94.59, 86.06, 79.94, 85.11],\n",
    "    \"CᴏᴍEM/R\": [89.67, 73.00, 96.00, 89.33, 99.00, 82.33, 90.33, 87.67],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df_melt = pd.melt(df, id_vars=\"Dataset\", var_name=\"Strategy_Metric\", value_name=\"Score\")\n",
    "df_melt[[\"Method\", \"Metric\"]] = df_melt[\"Strategy_Metric\"].str.split(\"/\", expand=True)\n",
    "df_melt = df_melt.drop(\"Strategy_Metric\", axis=1)\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "plt.ylim(45, 100)\n",
    "g = sns.barplot(\n",
    "    x=\"Method\",\n",
    "    y=\"Score\",\n",
    "    hue=\"Metric\",\n",
    "    data=df_melt,\n",
    "    capsize=0.2,\n",
    "    errorbar=(\"sd\", 0.60),\n",
    ")\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"precision_recall.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams[\"axes.unicode_minus\"] = False\n",
    "data1 = {\n",
    "    \"Position\": list(range(1, 11))[1::2],\n",
    "    \"CᴏᴍEM\": [85.61] * 5,\n",
    "    \"Selecting\": [75.83, 85.01, 86.62, 85.77, 84.38, 79.88, 82.89, 79.45, 79.29, 74.80][\n",
    "        1::2\n",
    "    ],\n",
    "    \"Comparing\": [81.07, 71.21, 68.98, 67.86, 66.41, 65.57, 64.49, 63.60, 63.08, 62.26][\n",
    "        1::2\n",
    "    ],\n",
    "    \"Matching\": [64.02] * 5,\n",
    "}\n",
    "data2 = {\n",
    "    \"Position\": list(range(1, 11))[1::2],\n",
    "    \"CᴏᴍEM\": [85.53] * 5,\n",
    "    \"Selecting\": [85.15, 78.85, 83.28, 81.71, 85.10, 83.26, 83.32, 82.10, 82.24, 80.84][\n",
    "        1::2\n",
    "    ],\n",
    "    \"Comparing\": [82.07, 82.25, 82.71, 83.22, 83.62, 83.99, 84.70, 85.03, 85.93, 87.54][\n",
    "        ::-1\n",
    "    ][1::2],\n",
    "    \"Matching\": [67.80] * 5,\n",
    "}\n",
    "df1 = pd.DataFrame(data1)\n",
    "df1 = pd.melt(df1, id_vars=\"Position\", var_name=\"Strategy\", value_name=\"F1 Score\")\n",
    "df1[\"LLM\"] = \"GPT-3.5 Turbo\"\n",
    "df2 = pd.DataFrame(data2)\n",
    "df2 = pd.melt(df2, id_vars=\"Position\", var_name=\"Strategy\", value_name=\"F1 Score\")\n",
    "df2[\"LLM\"] = \"GPT-4o Mini\"\n",
    "df = pd.concat([df1, df2])\n",
    "\n",
    "# sns.lineplot(x=\"Position\", y=\"F1 Score\", hue=\"Strategy\", style=\"Strategy\", dashes=True, markers=True, data=df_melt, markersize=7).set(xlabel='Matching Record Position')\n",
    "# sns.despine()\n",
    "# plt.tight_layout()\n",
    "\n",
    "g = sns.FacetGrid(df, col=\"LLM\", sharey=False, legend_out=False, height=4.5)\n",
    "g.set_titles(\"{col_name}\")\n",
    "g.map_dataframe(\n",
    "    sns.lineplot,\n",
    "    x=\"Position\",\n",
    "    y=\"F1 Score\",\n",
    "    hue=\"Strategy\",\n",
    "    style=\"Strategy\",\n",
    "    dashes=True,\n",
    "    markers=True,\n",
    "    markersize=7,\n",
    ")\n",
    "g.set(xlabel=\"Matching Record Position\")\n",
    "g.add_legend()\n",
    "sns.move_legend(g, loc=\"center right\", bbox_to_anchor=(1, 0.4))\n",
    "g.tight_layout()\n",
    "plt.savefig(\"position.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "    \"LLM\": [\n",
    "        \"Mistral\",\n",
    "        \"Mistral\",\n",
    "        \"Mistral\",\n",
    "        \"Mistral\",\n",
    "        \"Mistral\",\n",
    "        \"Mistral\",\n",
    "        \"Mistral\",\n",
    "        \"Mistral\",\n",
    "        \"Solar\",\n",
    "        \"Solar\",\n",
    "        \"Solar\",\n",
    "        \"Solar\",\n",
    "        \"Flan\",\n",
    "        \"Flan\",\n",
    "        \"Flan\",\n",
    "        \"Flan\",\n",
    "        \"Flan\",\n",
    "        \"Flan\",\n",
    "        \"Flan\",\n",
    "        \"Flan\",\n",
    "        \"Command-R\",\n",
    "        \"Command-R\",\n",
    "        \"Command-R\",\n",
    "        \"Command-R\",\n",
    "        \"Llama3.1\",\n",
    "        \"Llama3.1\",\n",
    "        \"Llama3.1\",\n",
    "        \"Llama3.1\",\n",
    "        \"Qwen2\",\n",
    "        \"Qwen2\",\n",
    "        \"Qwen2\",\n",
    "        \"Qwen2\",\n",
    "    ],\n",
    "    \"Size (B)\": [\n",
    "        7,\n",
    "        7,\n",
    "        7,\n",
    "        7,\n",
    "        56,\n",
    "        56,\n",
    "        56,\n",
    "        56,\n",
    "        11,\n",
    "        11,\n",
    "        11,\n",
    "        11,\n",
    "        11,\n",
    "        11,\n",
    "        11,\n",
    "        11,\n",
    "        20,\n",
    "        20,\n",
    "        20,\n",
    "        20,\n",
    "        35,\n",
    "        35,\n",
    "        35,\n",
    "        35,\n",
    "        8,\n",
    "        8,\n",
    "        8,\n",
    "        8,\n",
    "        7,\n",
    "        7,\n",
    "        7,\n",
    "        7,\n",
    "    ],\n",
    "    \"Strategy\": [\"Matching\", \"Comparing\", \"Selecting\", \"CᴏᴍEM\"] * 8,\n",
    "    \"Precision\": [\n",
    "        34.24,\n",
    "        66.38,\n",
    "        69.19,\n",
    "        69.27,\n",
    "        66.27,\n",
    "        84.48,\n",
    "        72.40,\n",
    "        76.70,\n",
    "        53.38,\n",
    "        81.68,\n",
    "        64.29,\n",
    "        63.16,\n",
    "        72.13,\n",
    "        89.41,\n",
    "        68.88,\n",
    "        69.26,\n",
    "        63.93,\n",
    "        87.14,\n",
    "        68.36,\n",
    "        70.02,\n",
    "        40.29,\n",
    "        72.36,\n",
    "        69.10,\n",
    "        69.54,\n",
    "        38.11,\n",
    "        80.57,\n",
    "        67.87,\n",
    "        70.77,\n",
    "        48.32,\n",
    "        81.25,\n",
    "        66.08,\n",
    "        72.52,\n",
    "    ],\n",
    "    \"Recall\": [\n",
    "        83.83,\n",
    "        48.92,\n",
    "        79.46,\n",
    "        84.29,\n",
    "        66.04,\n",
    "        51.33,\n",
    "        87.38,\n",
    "        91.29,\n",
    "        72.88,\n",
    "        61.37,\n",
    "        78.46,\n",
    "        79.29,\n",
    "        72.46,\n",
    "        64.38,\n",
    "        89.21,\n",
    "        90.62,\n",
    "        79.29,\n",
    "        70.42,\n",
    "        89.29,\n",
    "        91.12,\n",
    "        98.21,\n",
    "        72.21,\n",
    "        90.58,\n",
    "        91.54,\n",
    "        85.71,\n",
    "        73.96,\n",
    "        87.25,\n",
    "        92.50,\n",
    "        89.71,\n",
    "        76.33,\n",
    "        86.54,\n",
    "        92.38,\n",
    "    ],\n",
    "    \"F1\": [\n",
    "        45.91,\n",
    "        54.82,\n",
    "        73.80,\n",
    "        75.94,\n",
    "        62.39,\n",
    "        61.80,\n",
    "        79.09,\n",
    "        83.29,\n",
    "        57.04,\n",
    "        67.67,\n",
    "        70.60,\n",
    "        70.29,\n",
    "        71.18,\n",
    "        73.60,\n",
    "        77.72,\n",
    "        78.51,\n",
    "        69.19,\n",
    "        76.37,\n",
    "        77.43,\n",
    "        79.18,\n",
    "        54.52,\n",
    "        72.20,\n",
    "        78.39,\n",
    "        79.03,\n",
    "        47.75,\n",
    "        75.90,\n",
    "        76.33,\n",
    "        80.17,\n",
    "        62.11,\n",
    "        78.34,\n",
    "        74.93,\n",
    "        81.24,\n",
    "    ],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "sns.set_theme(style=\"ticks\", font_scale=1.2)\n",
    "plt.figure()\n",
    "g = sns.FacetGrid(df, col=\"Strategy\", col_wrap=4, legend_out=False)\n",
    "g.map_dataframe(\n",
    "    sns.scatterplot,\n",
    "    x=\"Recall\",\n",
    "    y=\"Precision\",\n",
    "    style=\"LLM\",\n",
    "    hue=\"LLM\",\n",
    "    size=\"Size (B)\",\n",
    "    sizes=(40, 100),\n",
    "    s=100,\n",
    "    legend=\"brief\",\n",
    ")\n",
    "g.set_titles(\"{col_name}\")\n",
    "\n",
    "\n",
    "def plot_f1_lines(ax):\n",
    "    f1_scores = range(50, 100, 10)\n",
    "    xmin, xmax = ax.get_xlim()\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "\n",
    "    precision = np.linspace(ymin, ymax, 100)\n",
    "    for f1 in f1_scores:\n",
    "        recall = (f1 * precision) / (2 * precision - f1)\n",
    "        # Filter out invalid recall values\n",
    "        recall[(recall > 100) | (recall < 0)] = np.nan\n",
    "        valid_indices = ~np.isnan(recall)\n",
    "        recall = recall[valid_indices]\n",
    "        precision = precision[valid_indices]\n",
    "        ax.plot(\n",
    "            recall,\n",
    "            precision,\n",
    "            linestyle=\"--\",\n",
    "            color=\"grey\",\n",
    "            alpha=f1 / 100,\n",
    "            label=\"F1 Score\",\n",
    "        )\n",
    "        if f1 in [60, 80]:\n",
    "            ax.text(\n",
    "                recall[-3],\n",
    "                precision[-3],\n",
    "                f\"{f1}\",\n",
    "                fontsize=9,\n",
    "                verticalalignment=\"bottom\",\n",
    "            )\n",
    "\n",
    "\n",
    "for ax in g.axes:\n",
    "    plot_f1_lines(ax)\n",
    "\n",
    "g.axes[0].plot(\n",
    "    86.58,\n",
    "    59.01,\n",
    "    marker=\"*\",\n",
    "    color=\".3\",\n",
    "    markersize=12,\n",
    "    fillstyle=\"none\",\n",
    "    label=\"GPT-4o\",\n",
    "    linestyle=\"\",\n",
    ")\n",
    "g.axes[1].plot(\n",
    "    82.17,\n",
    "    87.55,\n",
    "    marker=\"*\",\n",
    "    color=\".3\",\n",
    "    markersize=12,\n",
    "    fillstyle=\"none\",\n",
    "    label=\"GPT-4o\",\n",
    "    linestyle=\"\",\n",
    ")\n",
    "g.axes[2].plot(\n",
    "    86.08,\n",
    "    78.94,\n",
    "    marker=\"*\",\n",
    "    color=\".3\",\n",
    "    markersize=12,\n",
    "    fillstyle=\"none\",\n",
    "    label=\"GPT-4o\",\n",
    "    linestyle=\"\",\n",
    ")\n",
    "g.axes[3].plot(\n",
    "    88.62,\n",
    "    84.90,\n",
    "    marker=\"*\",\n",
    "    color=\".3\",\n",
    "    markersize=12,\n",
    "    fillstyle=\"none\",\n",
    "    label=\"GPT-4o\",\n",
    "    linestyle=\"\",\n",
    ")\n",
    "\n",
    "labels = list(g._legend_data.keys())\n",
    "handles = [g._legend_data[k] for k in labels]\n",
    "h, l = g.axes[0].get_legend_handles_labels()\n",
    "\n",
    "handles.insert(7, h[-1])\n",
    "labels.insert(7, l[-1])\n",
    "handles.append(h[-2])\n",
    "labels.append(l[-2])\n",
    "\n",
    "\n",
    "def reorder(labels):\n",
    "    sizes_and_scores = labels[8:]\n",
    "    names = labels[:8]\n",
    "\n",
    "    new_labels = []\n",
    "    for i in range(len(names) - 1):\n",
    "        new_labels.append(names[i])\n",
    "        new_labels.append(sizes_and_scores[i])\n",
    "\n",
    "    new_labels.append(names[-1])\n",
    "    new_labels.append(sizes_and_scores[-1])\n",
    "    return new_labels\n",
    "\n",
    "\n",
    "labels = reorder(labels)\n",
    "handles = reorder(handles)\n",
    "\n",
    "legend_data = {label: handles for label, handles in zip(labels, handles, strict=False)}\n",
    "\n",
    "sns.despine()\n",
    "g.add_legend(legend_data)\n",
    "sns.move_legend(\n",
    "    g,\n",
    "    \"lower center\",\n",
    "    bbox_to_anchor=(0.5, -0.2),\n",
    "    frameon=False,\n",
    "    ncol=8,\n",
    "    markerscale=1,\n",
    "    columnspacing=0.5,\n",
    ")\n",
    "g.tight_layout()\n",
    "plt.savefig(\"llms.pdf\", bbox_inches=\"tight\")\n",
    "sns.set_theme(style=\"ticks\", rc={\"axes.formatter.limits\": (-4, 5)}, font_scale=1.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Dataset\": [\n",
    "        \"Abt-Buy\",\n",
    "        \"Amazon-Google\",\n",
    "        \"DBLP-ACM\",\n",
    "        \"DBLP-Scholar\",\n",
    "        \"IMDB-TMDB\",\n",
    "        \"IMDB-TVDB\",\n",
    "        \"TMDB-TVDB\",\n",
    "        \"Walmart-Amazon\",\n",
    "        \"Abt-Buy\",\n",
    "        \"Amazon-Google\",\n",
    "        \"DBLP-ACM\",\n",
    "        \"DBLP-Scholar\",\n",
    "        \"IMDB-TMDB\",\n",
    "        \"IMDB-TVDB\",\n",
    "        \"TMDB-TVDB\",\n",
    "        \"Walmart-Amazon\",\n",
    "        \"Abt-Buy\",\n",
    "        \"Amazon-Google\",\n",
    "        \"DBLP-ACM\",\n",
    "        \"IMDB-TMDB\",\n",
    "        \"IMDB-TVDB\",\n",
    "        \"TMDB-TVDB\",\n",
    "        \"Walmart-Amazon\",\n",
    "        \"DBLP-Scholar\",\n",
    "        \"Abt-Buy\",\n",
    "        \"Amazon-Google\",\n",
    "        \"DBLP-ACM\",\n",
    "        \"DBLP-Scholar\",\n",
    "        \"IMDB-TMDB\",\n",
    "        \"IMDB-TVDB\",\n",
    "        \"TMDB-TVDB\",\n",
    "        \"Walmart-Amazon\",\n",
    "    ],\n",
    "    \"Model\": [\n",
    "        \"flan-t5-base\",\n",
    "        \"flan-t5-base\",\n",
    "        \"flan-t5-base\",\n",
    "        \"flan-t5-base\",\n",
    "        \"flan-t5-base\",\n",
    "        \"flan-t5-base\",\n",
    "        \"flan-t5-base\",\n",
    "        \"flan-t5-base\",\n",
    "        \"flan-t5-large\",\n",
    "        \"flan-t5-large\",\n",
    "        \"flan-t5-large\",\n",
    "        \"flan-t5-large\",\n",
    "        \"flan-t5-large\",\n",
    "        \"flan-t5-large\",\n",
    "        \"flan-t5-large\",\n",
    "        \"flan-t5-large\",\n",
    "        \"flan-t5-xl\",\n",
    "        \"flan-t5-xl\",\n",
    "        \"flan-t5-xl\",\n",
    "        \"flan-t5-xl\",\n",
    "        \"flan-t5-xl\",\n",
    "        \"flan-t5-xl\",\n",
    "        \"flan-t5-xl\",\n",
    "        \"flan-t5-xl\",\n",
    "        \"flan-t5-xxl\",\n",
    "        \"flan-t5-xxl\",\n",
    "        \"flan-t5-xxl\",\n",
    "        \"flan-t5-xxl\",\n",
    "        \"flan-t5-xxl\",\n",
    "        \"flan-t5-xxl\",\n",
    "        \"flan-t5-xxl\",\n",
    "        \"flan-t5-xxl\",\n",
    "    ],\n",
    "    \"Parameter\": [\n",
    "        250,\n",
    "        250,\n",
    "        250,\n",
    "        250,\n",
    "        250,\n",
    "        250,\n",
    "        250,\n",
    "        250,\n",
    "        780,\n",
    "        780,\n",
    "        780,\n",
    "        780,\n",
    "        780,\n",
    "        780,\n",
    "        780,\n",
    "        780,\n",
    "        3000,\n",
    "        3000,\n",
    "        3000,\n",
    "        3000,\n",
    "        3000,\n",
    "        3000,\n",
    "        3000,\n",
    "        3000,\n",
    "        11000,\n",
    "        11000,\n",
    "        11000,\n",
    "        11000,\n",
    "        11000,\n",
    "        11000,\n",
    "        11000,\n",
    "        11000,\n",
    "    ],  # Parameter size in million (M)\n",
    "    \"Matching\": [\n",
    "        55.00,\n",
    "        33.33,\n",
    "        70.33,\n",
    "        64.00,\n",
    "        78.67,\n",
    "        65.33,\n",
    "        89.67,\n",
    "        26.00,\n",
    "        91.33,\n",
    "        75.67,\n",
    "        99.33,\n",
    "        94.67,\n",
    "        95.33,\n",
    "        93.33,\n",
    "        99.00,\n",
    "        79.00,\n",
    "        92.33,\n",
    "        79.67,\n",
    "        98.67,\n",
    "        95.67,\n",
    "        99.33,\n",
    "        99.33,\n",
    "        99.33,\n",
    "        84.00,\n",
    "        94.33,\n",
    "        84.00,\n",
    "        98.67,\n",
    "        94.33,\n",
    "        99.67,\n",
    "        96.00,\n",
    "        99.33,\n",
    "        92.67,\n",
    "    ],\n",
    "    #'Matching': [85.33,69.00,89.00,89.00,94.33,95.33,97.33,60.67,98.67,96.00,100.00,99.00,99.67,99.67,100.00,98.33,99.33,98.33,100.00,99.33,100.00,100.00,100.00,99.33,99.33,98.00,99.67,99.33,100.00,99.67,100.00,99.33],\n",
    "    \"Comparing$_{\\mathrm{all\\u2010pair}}$\": [\n",
    "        28.00,\n",
    "        16.67,\n",
    "        10.33,\n",
    "        5.67,\n",
    "        19.67,\n",
    "        20.00,\n",
    "        20.00,\n",
    "        11.67,\n",
    "        89.00,\n",
    "        62.33,\n",
    "        88.33,\n",
    "        64.67,\n",
    "        52.67,\n",
    "        20.00,\n",
    "        24.67,\n",
    "        58.00,\n",
    "        91.67,\n",
    "        82.67,\n",
    "        98.33,\n",
    "        92.00,\n",
    "        97.33,\n",
    "        88.00,\n",
    "        94.00,\n",
    "        85.00,\n",
    "        94.00,\n",
    "        77.33,\n",
    "        97.33,\n",
    "        92.33,\n",
    "        94.67,\n",
    "        70.67,\n",
    "        94.00,\n",
    "        93.67,\n",
    "    ],\n",
    "    #'Comparing': [59.67,44.33,25.00,20.33,43.33,35.00,53.00,39.67,98.33,92.67,99.00,92.67,66.00,46.00,44.33,80.33,99.33,99.33,100.00,98.67,100.00,98.67,99.00,96.67,99.33,99.33,100.00,99.67,99.33,96.67,98.67,100.00,],\n",
    "    # u\"Comparing$_{\\mathrm{all\\u2010pair}}$\": [],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df[\"Parameter\"] = df[\"Parameter\"] / 1000\n",
    "df_melt = pd.melt(\n",
    "    df,\n",
    "    id_vars=[\"Dataset\", \"Model\", \"Parameter\"],\n",
    "    var_name=\"Strategy\",\n",
    "    value_name=\"Recall@1\",\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(4.8 * 1.4, 4.8))\n",
    "\n",
    "# Plot recall@1\n",
    "lineplot = sns.lineplot(\n",
    "    x=\"Parameter\",\n",
    "    y=\"Recall@1\",\n",
    "    hue=\"Strategy\",\n",
    "    style=\"Strategy\",\n",
    "    markers=True,\n",
    "    data=df_melt,\n",
    ")\n",
    "lineplot.set(xlabel=\"Parameter Size (in Billions)\")\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"matching_comparing.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = {\n",
    "    \"Dataset\": [\n",
    "        \"Abt-Buy\",\n",
    "        \"Amazon-Google\",\n",
    "        \"DBLP-ACM\",\n",
    "        \"DBLP-Scholar\",\n",
    "        \"IMDB-TMDB\",\n",
    "        \"IMDB-TVDB\",\n",
    "        \"TMDB-TVDB\",\n",
    "        \"Walmart-Amazon\",\n",
    "    ]\n",
    "    * 5,\n",
    "    \"$k$\": [\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        2,\n",
    "        2,\n",
    "        2,\n",
    "        2,\n",
    "        2,\n",
    "        2,\n",
    "        2,\n",
    "        2,\n",
    "        3,\n",
    "        3,\n",
    "        3,\n",
    "        3,\n",
    "        3,\n",
    "        3,\n",
    "        3,\n",
    "        3,\n",
    "        4,\n",
    "        4,\n",
    "        4,\n",
    "        4,\n",
    "        4,\n",
    "        4,\n",
    "        4,\n",
    "        4,\n",
    "        5,\n",
    "        5,\n",
    "        5,\n",
    "        5,\n",
    "        5,\n",
    "        5,\n",
    "        5,\n",
    "        5,\n",
    "    ],\n",
    "    \"F1\": [\n",
    "        86.33,\n",
    "        62.23,\n",
    "        94.98,\n",
    "        77.95,\n",
    "        79.45,\n",
    "        41.90,\n",
    "        80.52,\n",
    "        80.56,\n",
    "        80.23,\n",
    "        47.74,\n",
    "        91.15,\n",
    "        81.21,\n",
    "        78.90,\n",
    "        57.02,\n",
    "        88.42,\n",
    "        53.70,\n",
    "        82.08,\n",
    "        65.86,\n",
    "        83.55,\n",
    "        71.28,\n",
    "        92.88,\n",
    "        80.94,\n",
    "        85.53,\n",
    "        81.17,\n",
    "        87.62,\n",
    "        69.63,\n",
    "        90.85,\n",
    "        84.68,\n",
    "        96.74,\n",
    "        84.16,\n",
    "        84.82,\n",
    "        86.37,\n",
    "        86.13,\n",
    "        71.41,\n",
    "        92.04,\n",
    "        85.63,\n",
    "        96.42,\n",
    "        86.01,\n",
    "        86.83,\n",
    "        84.83,\n",
    "    ],\n",
    "    \"P\": [\n",
    "        93.75,\n",
    "        67.58,\n",
    "        92.43,\n",
    "        90.71,\n",
    "        97.57,\n",
    "        83.17,\n",
    "        90.79,\n",
    "        84.06,\n",
    "        92.21,\n",
    "        62.37,\n",
    "        91.30,\n",
    "        86.74,\n",
    "        96.62,\n",
    "        80.98,\n",
    "        86.58,\n",
    "        87.88,\n",
    "        88.76,\n",
    "        68.21,\n",
    "        80.94,\n",
    "        72.26,\n",
    "        94.48,\n",
    "        87.89,\n",
    "        81.76,\n",
    "        84.23,\n",
    "        85.67,\n",
    "        66.57,\n",
    "        86.23,\n",
    "        80.48,\n",
    "        94.59,\n",
    "        86.06,\n",
    "        79.94,\n",
    "        85.11,\n",
    "        83.44,\n",
    "        66.57,\n",
    "        86.51,\n",
    "        79.83,\n",
    "        94.27,\n",
    "        88.11,\n",
    "        81.95,\n",
    "        79.19,\n",
    "    ],\n",
    "    \"R\": [\n",
    "        80.00,\n",
    "        57.67,\n",
    "        97.67,\n",
    "        68.33,\n",
    "        67.00,\n",
    "        28.00,\n",
    "        72.33,\n",
    "        77.33,\n",
    "        71.00,\n",
    "        38.67,\n",
    "        91.00,\n",
    "        76.33,\n",
    "        66.67,\n",
    "        44.00,\n",
    "        90.33,\n",
    "        38.67,\n",
    "        76.33,\n",
    "        63.67,\n",
    "        86.33,\n",
    "        70.33,\n",
    "        91.33,\n",
    "        75.00,\n",
    "        89.67,\n",
    "        78.33,\n",
    "        89.67,\n",
    "        73.00,\n",
    "        96.00,\n",
    "        89.33,\n",
    "        99.00,\n",
    "        82.33,\n",
    "        90.33,\n",
    "        87.67,\n",
    "        89.00,\n",
    "        77.00,\n",
    "        98.33,\n",
    "        92.33,\n",
    "        98.67,\n",
    "        84.00,\n",
    "        92.33,\n",
    "        91.33,\n",
    "    ],\n",
    "}\n",
    "data2 = {\n",
    "    \"Dataset\": [\n",
    "        \"Abt-Buy\",\n",
    "        \"Amazon-Google\",\n",
    "        \"DBLP-ACM\",\n",
    "        \"DBLP-Scholar\",\n",
    "        \"IMDB-TMDB\",\n",
    "        \"IMDB-TVDB\",\n",
    "        \"TMDB-TVDB\",\n",
    "        \"Walmart-Amazon\",\n",
    "    ]\n",
    "    * 5,\n",
    "    \"$k$\": [\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        2,\n",
    "        2,\n",
    "        2,\n",
    "        2,\n",
    "        2,\n",
    "        2,\n",
    "        2,\n",
    "        2,\n",
    "        3,\n",
    "        3,\n",
    "        3,\n",
    "        3,\n",
    "        3,\n",
    "        3,\n",
    "        3,\n",
    "        3,\n",
    "        4,\n",
    "        4,\n",
    "        4,\n",
    "        4,\n",
    "        4,\n",
    "        4,\n",
    "        4,\n",
    "        4,\n",
    "        5,\n",
    "        5,\n",
    "        5,\n",
    "        5,\n",
    "        5,\n",
    "        5,\n",
    "        5,\n",
    "        5,\n",
    "    ],\n",
    "    \"F1\": [\n",
    "        88.71,\n",
    "        69.76,\n",
    "        92.04,\n",
    "        86.97,\n",
    "        97.14,\n",
    "        86.00,\n",
    "        91.81,\n",
    "        82.70,\n",
    "        88.78,\n",
    "        70.68,\n",
    "        91.64,\n",
    "        86.94,\n",
    "        96.10,\n",
    "        76.58,\n",
    "        91.64,\n",
    "        88.04,\n",
    "        88.60,\n",
    "        70.44,\n",
    "        90.05,\n",
    "        88.99,\n",
    "        95.25,\n",
    "        79.11,\n",
    "        91.32,\n",
    "        89.00,\n",
    "        88.24,\n",
    "        71.47,\n",
    "        90.58,\n",
    "        87.84,\n",
    "        95.62,\n",
    "        78.07,\n",
    "        90.97,\n",
    "        88.56,\n",
    "        88.85,\n",
    "        71.61,\n",
    "        90.94,\n",
    "        87.61,\n",
    "        95.25,\n",
    "        78.31,\n",
    "        90.85,\n",
    "        88.30,\n",
    "    ],\n",
    "    \"P\": [\n",
    "        87.14,\n",
    "        67.08,\n",
    "        86.51,\n",
    "        79.72,\n",
    "        97.97,\n",
    "        87.03,\n",
    "        88.54,\n",
    "        81.76,\n",
    "        86.67,\n",
    "        69.11,\n",
    "        85.55,\n",
    "        80.63,\n",
    "        97.92,\n",
    "        86.55,\n",
    "        88.51,\n",
    "        87.75,\n",
    "        85.45,\n",
    "        68.34,\n",
    "        83.29,\n",
    "        82.20,\n",
    "        96.90,\n",
    "        88.80,\n",
    "        88.20,\n",
    "        87.70,\n",
    "        85.36,\n",
    "        68.83,\n",
    "        83.24,\n",
    "        80.73,\n",
    "        96.60,\n",
    "        88.24,\n",
    "        88.12,\n",
    "        88.12,\n",
    "        86.21,\n",
    "        67.96,\n",
    "        84.33,\n",
    "        80.11,\n",
    "        96.90,\n",
    "        87.30,\n",
    "        87.62,\n",
    "        87.30,\n",
    "    ],\n",
    "    \"R\": [\n",
    "        90.33,\n",
    "        72.67,\n",
    "        98.33,\n",
    "        95.67,\n",
    "        96.33,\n",
    "        85.00,\n",
    "        95.33,\n",
    "        83.67,\n",
    "        91.00,\n",
    "        72.33,\n",
    "        98.67,\n",
    "        94.33,\n",
    "        94.33,\n",
    "        68.67,\n",
    "        95.00,\n",
    "        88.33,\n",
    "        92.00,\n",
    "        72.67,\n",
    "        98.00,\n",
    "        97.00,\n",
    "        93.67,\n",
    "        71.33,\n",
    "        94.67,\n",
    "        90.33,\n",
    "        91.33,\n",
    "        74.33,\n",
    "        99.33,\n",
    "        96.33,\n",
    "        94.67,\n",
    "        70.00,\n",
    "        94.00,\n",
    "        89.00,\n",
    "        91.67,\n",
    "        75.67,\n",
    "        98.67,\n",
    "        96.67,\n",
    "        93.67,\n",
    "        71.00,\n",
    "        94.33,\n",
    "        89.33,\n",
    "    ],\n",
    "}\n",
    "\n",
    "df1 = pd.DataFrame(data1)\n",
    "df1 = df1.melt(id_vars=[\"Dataset\", \"$k$\"], var_name=\"Metric\", value_name=\"Score\")\n",
    "df1[\"LLM\"] = \"GPT-3.5 Turbo\"\n",
    "df2 = pd.DataFrame(data2)\n",
    "df2 = df2.melt(id_vars=[\"Dataset\", \"$k$\"], var_name=\"Metric\", value_name=\"Score\")\n",
    "df2[\"LLM\"] = \"GPT-4o Mini\"\n",
    "df = pd.concat([df1, df2])\n",
    "\n",
    "g = sns.FacetGrid(df, col=\"LLM\", sharey=False, legend_out=False, height=4.5)\n",
    "g.set_titles(\"{col_name}\")\n",
    "g.map_dataframe(\n",
    "    sns.lineplot,\n",
    "    x=\"$k$\",\n",
    "    y=\"Score\",\n",
    "    style=\"Metric\",\n",
    "    markers=True,\n",
    "    hue=\"Metric\",\n",
    "    err_style=\"band\",\n",
    "    errorbar=(\"pi\", 60),\n",
    ")\n",
    "g.axes[0][0].set_ylim(40, 100)\n",
    "g.axes[0][1].set_ylim(70, 100)\n",
    "g.set(xticks=range(1, 6))\n",
    "g.add_legend()\n",
    "g.tight_layout()\n",
    "\n",
    "plt.savefig(\"top_k.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Dataset\": [\n",
    "        \"Abt-Buy\",\n",
    "        \"Amazon-Google\",\n",
    "        \"DBLP-ACM\",\n",
    "        \"DBLP-Scholar\",\n",
    "        \"IMDB-TMDB\",\n",
    "        \"IMDB-TVDB\",\n",
    "        \"TMDB-TVDB\",\n",
    "        \"Walmart-Amazon\",\n",
    "    ]\n",
    "    * 5,\n",
    "    \"$k$\": [\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        2,\n",
    "        2,\n",
    "        2,\n",
    "        2,\n",
    "        2,\n",
    "        2,\n",
    "        2,\n",
    "        2,\n",
    "        3,\n",
    "        3,\n",
    "        3,\n",
    "        3,\n",
    "        3,\n",
    "        3,\n",
    "        3,\n",
    "        3,\n",
    "        4,\n",
    "        4,\n",
    "        4,\n",
    "        4,\n",
    "        4,\n",
    "        4,\n",
    "        4,\n",
    "        4,\n",
    "        5,\n",
    "        5,\n",
    "        5,\n",
    "        5,\n",
    "        5,\n",
    "        5,\n",
    "        5,\n",
    "        5,\n",
    "    ],\n",
    "    \"F1\": [\n",
    "        # 86.33,62.23,94.98,77.95,79.45,41.90,80.52,80.56,80.23,47.74,91.15,81.21,78.90,57.02,88.42,53.70,82.08,65.86,83.55,71.28,92.88,80.94,85.53,81.17,87.62,69.63,90.85,84.68,96.74,84.16,84.82,86.37,86.13,71.41,92.04,85.63,96.42,86.01,86.83,84.83,\n",
    "        88.71,\n",
    "        69.76,\n",
    "        92.04,\n",
    "        86.97,\n",
    "        97.14,\n",
    "        86.00,\n",
    "        91.81,\n",
    "        82.70,\n",
    "        88.78,\n",
    "        70.68,\n",
    "        91.64,\n",
    "        86.94,\n",
    "        96.10,\n",
    "        76.58,\n",
    "        91.64,\n",
    "        88.04,\n",
    "        88.60,\n",
    "        70.44,\n",
    "        90.05,\n",
    "        88.99,\n",
    "        95.25,\n",
    "        79.11,\n",
    "        91.32,\n",
    "        89.00,\n",
    "        88.24,\n",
    "        71.47,\n",
    "        90.58,\n",
    "        87.84,\n",
    "        95.62,\n",
    "        78.07,\n",
    "        90.97,\n",
    "        88.56,\n",
    "        88.85,\n",
    "        71.61,\n",
    "        90.94,\n",
    "        87.61,\n",
    "        95.25,\n",
    "        78.31,\n",
    "        90.85,\n",
    "        88.30,\n",
    "    ],\n",
    "    \"P\": [\n",
    "        # 93.75,67.58,92.43,90.71,97.57,83.17,90.79,84.06,92.21,62.37,91.30,86.74,96.62,80.98,86.58,87.88,88.76,68.21,80.94,72.26,94.48,87.89,81.76,84.23,85.67,66.57,86.23,80.48,94.59,86.06,79.94,85.11,83.44,66.57,86.51,79.83,94.27,88.11,81.95,79.19,\n",
    "        87.14,\n",
    "        67.08,\n",
    "        86.51,\n",
    "        79.72,\n",
    "        97.97,\n",
    "        87.03,\n",
    "        88.54,\n",
    "        81.76,\n",
    "        86.67,\n",
    "        69.11,\n",
    "        85.55,\n",
    "        80.63,\n",
    "        97.92,\n",
    "        86.55,\n",
    "        88.51,\n",
    "        87.75,\n",
    "        85.45,\n",
    "        68.34,\n",
    "        83.29,\n",
    "        82.20,\n",
    "        96.90,\n",
    "        88.80,\n",
    "        88.20,\n",
    "        87.70,\n",
    "        85.36,\n",
    "        68.83,\n",
    "        83.24,\n",
    "        80.73,\n",
    "        96.60,\n",
    "        88.24,\n",
    "        88.12,\n",
    "        88.12,\n",
    "        86.21,\n",
    "        67.96,\n",
    "        84.33,\n",
    "        80.11,\n",
    "        96.90,\n",
    "        87.30,\n",
    "        87.62,\n",
    "        87.30,\n",
    "    ],\n",
    "    \"R\": [\n",
    "        # 80.00,57.67,97.67,68.33,67.00,28.00,72.33,77.33,71.00,38.67,91.00,76.33,66.67,44.00,90.33,38.67,76.33,63.67,86.33,70.33,91.33,75.00,89.67,78.33,89.67,73.00,96.00,89.33,99.00,82.33,90.33,87.67,89.00,77.00,98.33,92.33,98.67,84.00,92.33,91.33,\n",
    "        90.33,\n",
    "        72.67,\n",
    "        98.33,\n",
    "        95.67,\n",
    "        96.33,\n",
    "        85.00,\n",
    "        95.33,\n",
    "        83.67,\n",
    "        91.00,\n",
    "        72.33,\n",
    "        98.67,\n",
    "        94.33,\n",
    "        94.33,\n",
    "        68.67,\n",
    "        95.00,\n",
    "        88.33,\n",
    "        92.00,\n",
    "        72.67,\n",
    "        98.00,\n",
    "        97.00,\n",
    "        93.67,\n",
    "        71.33,\n",
    "        94.67,\n",
    "        90.33,\n",
    "        91.33,\n",
    "        74.33,\n",
    "        99.33,\n",
    "        96.33,\n",
    "        94.67,\n",
    "        70.00,\n",
    "        94.00,\n",
    "        89.00,\n",
    "        91.67,\n",
    "        75.67,\n",
    "        98.67,\n",
    "        96.67,\n",
    "        93.67,\n",
    "        71.00,\n",
    "        94.33,\n",
    "        89.33,\n",
    "    ],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df.melt(id_vars=[\"Dataset\", \"$k$\"], var_name=\"Metric\", value_name=\"Score\")\n",
    "\n",
    "sns.set_theme(style=\"ticks\", rc={\"axes.formatter.limits\": (-4, 5)}, font_scale=1.2)\n",
    "g = sns.FacetGrid(df, col=\"Dataset\", col_wrap=4, legend_out=True)\n",
    "g.set_titles(\"{col_name}\")\n",
    "g.map_dataframe(\n",
    "    sns.lineplot, x=\"$k$\", y=\"Score\", style=\"Metric\", markers=True, hue=\"Metric\"\n",
    ")\n",
    "sns.despine()\n",
    "g.add_legend()\n",
    "g.tight_layout()\n",
    "plt.savefig(\"top_k_full.pdf\")\n",
    "sns.set_theme(style=\"ticks\", rc={\"axes.formatter.limits\": (-4, 5)}, font_scale=1.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Dataset\": [\n",
    "        \"Abt-Buy\",\n",
    "        \"Amazon-Google\",\n",
    "        \"DBLP-ACM\",\n",
    "        \"DBLP-Scholar\",\n",
    "        \"IMDB-TMDB\",\n",
    "        \"IMDB-TVDB\",\n",
    "        \"TMDB-TVDB\",\n",
    "        \"Walmart-Amazon\",\n",
    "        \"Abt-Buy\",\n",
    "        \"Amazon-Google\",\n",
    "        \"DBLP-ACM\",\n",
    "        \"DBLP-Scholar\",\n",
    "        \"IMDB-TMDB\",\n",
    "        \"IMDB-TVDB\",\n",
    "        \"TMDB-TVDB\",\n",
    "        \"Walmart-Amazon\",\n",
    "        \"Abt-Buy\",\n",
    "        \"Amazon-Google\",\n",
    "        \"DBLP-ACM\",\n",
    "        \"DBLP-Scholar\",\n",
    "        \"IMDB-TMDB\",\n",
    "        \"IMDB-TVDB\",\n",
    "        \"TMDB-TVDB\",\n",
    "        \"Walmart-Amazon\",\n",
    "        \"Abt-Buy\",\n",
    "        \"Amazon-Google\",\n",
    "        \"DBLP-ACM\",\n",
    "        \"DBLP-Scholar\",\n",
    "        \"IMDB-TMDB\",\n",
    "        \"IMDB-TVDB\",\n",
    "        \"TMDB-TVDB\",\n",
    "        \"Walmart-Amazon\",\n",
    "    ],\n",
    "    \"Method\": [\"Matching\"] * 8 + [\"Selecting\"] * 8 + [\"M.+S.\"] * 8 + [\"CᴏᴍEM\"] * 8,\n",
    "    \"F1\": [\n",
    "        44.23,\n",
    "        35.47,\n",
    "        67.35,\n",
    "        66.13,\n",
    "        65.82,\n",
    "        57.59,\n",
    "        69.43,\n",
    "        41.84,\n",
    "        67.94,\n",
    "        53.79,\n",
    "        70.04,\n",
    "        67.40,\n",
    "        85.84,\n",
    "        72.73,\n",
    "        71.60,\n",
    "        65.64,\n",
    "        79.48,\n",
    "        56.20,\n",
    "        80.65,\n",
    "        73.98,\n",
    "        90.14,\n",
    "        78.76,\n",
    "        78.26,\n",
    "        81.25,\n",
    "        80.00,\n",
    "        58.78,\n",
    "        84.03,\n",
    "        72.44,\n",
    "        93.78,\n",
    "        79.38,\n",
    "        80.18,\n",
    "        74.01,\n",
    "    ],\n",
    "    \"Precision\": [\n",
    "        29.32,\n",
    "        25.00,\n",
    "        51.03,\n",
    "        55.41,\n",
    "        89.66,\n",
    "        60.44,\n",
    "        55.76,\n",
    "        27.16,\n",
    "        54.94,\n",
    "        43.29,\n",
    "        54.80,\n",
    "        53.18,\n",
    "        78.99,\n",
    "        69.72,\n",
    "        58.60,\n",
    "        53.46,\n",
    "        70.54,\n",
    "        47.89,\n",
    "        67.57,\n",
    "        62.33,\n",
    "        84.96,\n",
    "        81.72,\n",
    "        69.23,\n",
    "        73.39,\n",
    "        70.77,\n",
    "        49.66,\n",
    "        72.46,\n",
    "        59.74,\n",
    "        89.91,\n",
    "        81.91,\n",
    "        71.65,\n",
    "        66.14,\n",
    "    ],\n",
    "    \"Recall\": [\n",
    "        90.00,\n",
    "        61.00,\n",
    "        99.00,\n",
    "        82.00,\n",
    "        52.00,\n",
    "        55.00,\n",
    "        92.00,\n",
    "        91.00,\n",
    "        89.00,\n",
    "        71.00,\n",
    "        97.00,\n",
    "        92.00,\n",
    "        94.00,\n",
    "        76.00,\n",
    "        92.00,\n",
    "        85.00,\n",
    "        91.00,\n",
    "        68.00,\n",
    "        100.00,\n",
    "        91.00,\n",
    "        96.00,\n",
    "        76.00,\n",
    "        90.00,\n",
    "        91.00,\n",
    "        92.00,\n",
    "        72.00,\n",
    "        100.00,\n",
    "        92.00,\n",
    "        98.00,\n",
    "        77.00,\n",
    "        91.00,\n",
    "        84.00,\n",
    "    ],\n",
    "    \"Cost\": [\n",
    "        0.25,\n",
    "        0.24,\n",
    "        0.35,\n",
    "        0.33,\n",
    "        0.27,\n",
    "        0.24,\n",
    "        0.24,\n",
    "        0.39,\n",
    "        0.09,\n",
    "        0.09,\n",
    "        0.15,\n",
    "        0.12,\n",
    "        0.11,\n",
    "        0.08,\n",
    "        0.08,\n",
    "        0.17,\n",
    "        0.30,\n",
    "        0.29,\n",
    "        0.43,\n",
    "        0.39,\n",
    "        0.33,\n",
    "        0.29,\n",
    "        0.29,\n",
    "        0.47,\n",
    "        0.06,\n",
    "        0.06,\n",
    "        0.10,\n",
    "        0.09,\n",
    "        0.07,\n",
    "        0.05,\n",
    "        0.06,\n",
    "        0.10,\n",
    "    ],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df_melt = pd.melt(\n",
    "    df,\n",
    "    id_vars=[\"Dataset\", \"Method\"],\n",
    "    value_vars=[\"F1\", \"Precision\", \"Recall\"],\n",
    "    var_name=\"Metric\",\n",
    "    value_name=\"Score\",\n",
    ")\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "plt.ylim(30, 100)\n",
    "ax1 = sns.barplot(\n",
    "    x=\"Method\", y=\"Score\", hue=\"Metric\", data=df_melt, errorbar=(\"ci\", 90), capsize=0.2\n",
    ")\n",
    "sns.move_legend(ax1, \"upper left\")\n",
    "\n",
    "# Create a secondary y-axis for the cost\n",
    "ax2 = plt.twinx()\n",
    "color = sns.color_palette()[3]\n",
    "sns.swarmplot(data=df, x=\"Method\", y=\"Cost\", color=color, ax=ax2, alpha=0.6)\n",
    "sns.pointplot(\n",
    "    data=df,\n",
    "    x=\"Method\",\n",
    "    y=\"Cost\",\n",
    "    color=color,\n",
    "    ax=ax2,\n",
    "    alpha=0.9,\n",
    "    linestyle=\"none\",\n",
    "    errorbar=None,\n",
    "    marker=\"_\",\n",
    "    markersize=20,\n",
    "    markeredgewidth=3,\n",
    ")\n",
    "ax2.set_ylabel(\"Cost ($)\")\n",
    "\n",
    "sns.despine(right=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"comem.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Dataset\": [\n",
    "        \"Abt-Buy\",\n",
    "        \"Amazon-Google\",\n",
    "        \"DBLP-ACM\",\n",
    "        \"DBLP-Scholar\",\n",
    "        \"IMDB-TMDB\",\n",
    "        \"IMDB-TVDB\",\n",
    "        \"TMDB-TVDB\",\n",
    "        \"Walmart-Amazon\",\n",
    "        \"Abt-Buy\",\n",
    "        \"Amazon-Google\",\n",
    "        \"DBLP-ACM\",\n",
    "        \"DBLP-Scholar\",\n",
    "        \"IMDB-TMDB\",\n",
    "        \"IMDB-TVDB\",\n",
    "        \"TMDB-TVDB\",\n",
    "        \"Walmart-Amazon\",\n",
    "        \"Abt-Buy\",\n",
    "        \"Amazon-Google\",\n",
    "        \"DBLP-ACM\",\n",
    "        \"IMDB-TMDB\",\n",
    "        \"IMDB-TVDB\",\n",
    "        \"TMDB-TVDB\",\n",
    "        \"Walmart-Amazon\",\n",
    "        \"DBLP-Scholar\",\n",
    "        \"Abt-Buy\",\n",
    "        \"Amazon-Google\",\n",
    "        \"DBLP-ACM\",\n",
    "        \"DBLP-Scholar\",\n",
    "        \"IMDB-TMDB\",\n",
    "        \"IMDB-TVDB\",\n",
    "        \"TMDB-TVDB\",\n",
    "        \"Walmart-Amazon\",\n",
    "    ],\n",
    "    \"Model\": [\n",
    "        \"flan-t5-base\",\n",
    "        \"flan-t5-base\",\n",
    "        \"flan-t5-base\",\n",
    "        \"flan-t5-base\",\n",
    "        \"flan-t5-base\",\n",
    "        \"flan-t5-base\",\n",
    "        \"flan-t5-base\",\n",
    "        \"flan-t5-base\",\n",
    "        \"flan-t5-large\",\n",
    "        \"flan-t5-large\",\n",
    "        \"flan-t5-large\",\n",
    "        \"flan-t5-large\",\n",
    "        \"flan-t5-large\",\n",
    "        \"flan-t5-large\",\n",
    "        \"flan-t5-large\",\n",
    "        \"flan-t5-large\",\n",
    "        \"flan-t5-xl\",\n",
    "        \"flan-t5-xl\",\n",
    "        \"flan-t5-xl\",\n",
    "        \"flan-t5-xl\",\n",
    "        \"flan-t5-xl\",\n",
    "        \"flan-t5-xl\",\n",
    "        \"flan-t5-xl\",\n",
    "        \"flan-t5-xl\",\n",
    "        \"flan-t5-xxl\",\n",
    "        \"flan-t5-xxl\",\n",
    "        \"flan-t5-xxl\",\n",
    "        \"flan-t5-xxl\",\n",
    "        \"flan-t5-xxl\",\n",
    "        \"flan-t5-xxl\",\n",
    "        \"flan-t5-xxl\",\n",
    "        \"flan-t5-xxl\",\n",
    "    ],\n",
    "    \"Parameter\": [\n",
    "        250,\n",
    "        250,\n",
    "        250,\n",
    "        250,\n",
    "        250,\n",
    "        250,\n",
    "        250,\n",
    "        250,\n",
    "        780,\n",
    "        780,\n",
    "        780,\n",
    "        780,\n",
    "        780,\n",
    "        780,\n",
    "        780,\n",
    "        780,\n",
    "        3000,\n",
    "        3000,\n",
    "        3000,\n",
    "        3000,\n",
    "        3000,\n",
    "        3000,\n",
    "        3000,\n",
    "        3000,\n",
    "        11000,\n",
    "        11000,\n",
    "        11000,\n",
    "        11000,\n",
    "        11000,\n",
    "        11000,\n",
    "        11000,\n",
    "        11000,\n",
    "    ],  # Parameter size in million (M)\n",
    "    \"Matching/Recall@1\": [\n",
    "        55.00,\n",
    "        33.33,\n",
    "        70.33,\n",
    "        64.00,\n",
    "        78.67,\n",
    "        65.33,\n",
    "        89.67,\n",
    "        26.00,\n",
    "        91.33,\n",
    "        75.67,\n",
    "        99.33,\n",
    "        94.67,\n",
    "        95.33,\n",
    "        93.33,\n",
    "        99.00,\n",
    "        79.00,\n",
    "        92.33,\n",
    "        79.67,\n",
    "        98.67,\n",
    "        95.67,\n",
    "        99.33,\n",
    "        99.33,\n",
    "        99.33,\n",
    "        84.00,\n",
    "        94.33,\n",
    "        84.00,\n",
    "        98.67,\n",
    "        94.33,\n",
    "        99.67,\n",
    "        96.00,\n",
    "        99.33,\n",
    "        92.67,\n",
    "    ],\n",
    "    \"Matching/Recall@4\": [\n",
    "        85.33,\n",
    "        69.00,\n",
    "        89.00,\n",
    "        89.00,\n",
    "        94.33,\n",
    "        95.33,\n",
    "        97.33,\n",
    "        60.67,\n",
    "        98.67,\n",
    "        96.00,\n",
    "        100.00,\n",
    "        99.00,\n",
    "        99.67,\n",
    "        99.67,\n",
    "        100.00,\n",
    "        98.33,\n",
    "        99.33,\n",
    "        98.33,\n",
    "        100.00,\n",
    "        99.33,\n",
    "        100.00,\n",
    "        100.00,\n",
    "        100.00,\n",
    "        99.33,\n",
    "        99.33,\n",
    "        98.00,\n",
    "        99.67,\n",
    "        99.33,\n",
    "        100.00,\n",
    "        99.67,\n",
    "        100.00,\n",
    "        99.33,\n",
    "    ],\n",
    "    \"Comparing$_{\\mathrm{all\\u2010pair}}$/Recall@1\": [\n",
    "        28.00,\n",
    "        16.67,\n",
    "        10.33,\n",
    "        5.67,\n",
    "        19.67,\n",
    "        20.00,\n",
    "        20.00,\n",
    "        11.67,\n",
    "        89.00,\n",
    "        62.33,\n",
    "        88.33,\n",
    "        64.67,\n",
    "        52.67,\n",
    "        20.00,\n",
    "        24.67,\n",
    "        58.00,\n",
    "        91.67,\n",
    "        82.67,\n",
    "        98.33,\n",
    "        92.00,\n",
    "        97.33,\n",
    "        88.00,\n",
    "        94.00,\n",
    "        85.00,\n",
    "        94.00,\n",
    "        77.33,\n",
    "        97.33,\n",
    "        92.33,\n",
    "        94.67,\n",
    "        70.67,\n",
    "        94.00,\n",
    "        93.67,\n",
    "    ],\n",
    "    \"Comparing$_{\\mathrm{all\\u2010pair}}$/Recall@4\": [\n",
    "        59.67,\n",
    "        44.33,\n",
    "        25.00,\n",
    "        20.33,\n",
    "        43.33,\n",
    "        35.00,\n",
    "        53.00,\n",
    "        39.67,\n",
    "        98.33,\n",
    "        92.67,\n",
    "        99.00,\n",
    "        92.67,\n",
    "        66.00,\n",
    "        46.00,\n",
    "        44.33,\n",
    "        80.33,\n",
    "        99.33,\n",
    "        99.33,\n",
    "        100.00,\n",
    "        98.67,\n",
    "        100.00,\n",
    "        98.67,\n",
    "        99.00,\n",
    "        96.67,\n",
    "        99.33,\n",
    "        99.33,\n",
    "        100.00,\n",
    "        99.67,\n",
    "        99.33,\n",
    "        96.67,\n",
    "        98.67,\n",
    "        100.00,\n",
    "    ],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df[\"Parameter\"] = df[\"Parameter\"] / 1000\n",
    "df_melt = pd.melt(\n",
    "    df,\n",
    "    id_vars=[\"Dataset\", \"Model\", \"Parameter\"],\n",
    "    var_name=\"Strategy_Metric\",\n",
    "    value_name=\"Score\",\n",
    ")\n",
    "df_melt[[\"Strategy\", \"Metric\"]] = df_melt[\"Strategy_Metric\"].str.rsplit(\n",
    "    \"/\", expand=True\n",
    ")\n",
    "df_melt = df_melt.drop(\"Strategy_Metric\", axis=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig, axs = plt.subplots(1, 2, figsize=(9.6, 4.8), constrained_layout=True)\n",
    "\n",
    "# Plot recall@1\n",
    "sns.lineplot(\n",
    "    x=\"Parameter\",\n",
    "    y=\"Score\",\n",
    "    hue=\"Strategy\",\n",
    "    style=\"Strategy\",\n",
    "    markers=True,\n",
    "    data=df_melt[df_melt[\"Metric\"] == \"Recall@1\"],\n",
    "    ax=axs[0],\n",
    ")\n",
    "axs[0].set(title=\"Recall@1\", xlabel=\"Parameter Size (in Billions)\")\n",
    "\n",
    "# Plot recall@4\n",
    "sns.lineplot(\n",
    "    x=\"Parameter\",\n",
    "    y=\"Score\",\n",
    "    hue=\"Strategy\",\n",
    "    style=\"Strategy\",\n",
    "    markers=True,\n",
    "    data=df_melt[df_melt[\"Metric\"] == \"Recall@4\"],\n",
    "    ax=axs[1],\n",
    ")\n",
    "axs[1].set(title=\"Recall@4\", xlabel=\"Parameter Size (in Billions)\")\n",
    "\n",
    "sns.despine()\n",
    "plt.savefig(\"matching_comparing.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Percentage\": [20, 40, 60, 80, 100],\n",
    "    \"Matching_F1\": [38.57, 50.00, 54.03, 56.50, 58.69],\n",
    "    \"Matching_Precision\": [33.45, 49.74, 58.35, 64.69, 69.65],\n",
    "    \"Matching_Recall\": [53.12, 55.31, 54.79, 54.53, 54.88],\n",
    "    \"Selecting_F1\": [25.24, 42.09, 53.24, 62.70, 69.20],\n",
    "    \"Selecting_Precision\": [15.23, 28.50, 39.18, 49.37, 57.50],\n",
    "    \"Selecting_Recall\": [83.12, 86.56, 86.67, 88.28, 88.38],\n",
    "    # \"Hybrid_Precision\": [],\n",
    "    # \"Hybrid_Recall\": [],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df_melt = pd.melt(\n",
    "    df, id_vars=\"Percentage\", var_name=\"Strategy_Metric\", value_name=\"Score\"\n",
    ")\n",
    "df_melt[[\"Strategy\", \"Metric\"]] = df_melt[\"Strategy_Metric\"].str.split(\"_\", expand=True)\n",
    "df_melt = df_melt.drop(\"Strategy_Metric\", axis=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig, axs = plt.subplots(1, 2, figsize=(9.6, 4.8), constrained_layout=True)\n",
    "\n",
    "# Plot recall@1\n",
    "sns.lineplot(\n",
    "    x=\"Percentage\",\n",
    "    y=\"Score\",\n",
    "    hue=\"Metric\",\n",
    "    style=\"Metric\",\n",
    "    markers=True,\n",
    "    data=df_melt[df_melt[\"Strategy\"] == \"Matching\"],\n",
    "    ax=axs[0],\n",
    ")\n",
    "axs[0].set_title(\"Matching\")\n",
    "\n",
    "# Plot recall@5\n",
    "sns.lineplot(\n",
    "    x=\"Percentage\",\n",
    "    y=\"Score\",\n",
    "    hue=\"Metric\",\n",
    "    style=\"Metric\",\n",
    "    markers=True,\n",
    "    data=df_melt[df_melt[\"Strategy\"] == \"Selecting\"],\n",
    "    ax=axs[1],\n",
    ")\n",
    "axs[1].set_title(\"Selecting\")\n",
    "\n",
    "# sns.lineplot(x=\"Percentage\", y=\"Score\", hue=\"Metric\", style=\"Strategy\", data=df_melt)\n",
    "# g = sns.FacetGrid(df_melt, col=\"Strategy\", col_wrap=3, legend_out=False)\n",
    "# g.map_dataframe(sns.lineplot, x=\"Percentage\", y=\"Score\", style=\"Metric\", markers=True, hue=\"Metric\")\n",
    "g.add_legend()\n",
    "sns.despine()\n",
    "plt.savefig(\"matching_selecting.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"$k$\": list(range(10)),\n",
    "    \"Matching\": [745, 32, 14, 1, 2, 1, 0, 3, 0, 0],\n",
    "    \"Comparing\": [634, 76, 33, 14, 8, 13, 8, 5, 2, 5],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df_melt = pd.melt(df, id_vars=\"$k$\", var_name=\"Strategy\", value_name=\"Count\")\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "sns.barplot(x=\"$k$\", y=\"Count\", hue=\"Strategy\", data=df_melt)\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"ranking_recall.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Model\": [\"flan-t5-base\", \"flan-t5-large\", \"flan-t5-xl\", \"flan-t5-xxl\"],\n",
    "    \"Parameter\": [250, 780, 3000, 11000],  # Parameter size in million (M)\n",
    "    \"Precision\": [62.70, 68.85, 68.48, 69.53],\n",
    "    \"Recall\": [71.50, 86.12, 87.88, 87.25],\n",
    "    \"F1\": [66.42, 76.10, 76.52, 76.94],\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"Dataset\": [\n",
    "        \"Abt-Buy\",\n",
    "        \"Amazon-Google\",\n",
    "        \"DBLP-ACM\",\n",
    "        \"DBLP-Scholar\",\n",
    "        \"IMDB-TMDB\",\n",
    "        \"IMDB-TVDB\",\n",
    "        \"TMDB-TVDB\",\n",
    "        \"Walmart-Amazon\",\n",
    "        \"Abt-Buy\",\n",
    "        \"Amazon-Google\",\n",
    "        \"DBLP-ACM\",\n",
    "        \"DBLP-Scholar\",\n",
    "        \"IMDB-TMDB\",\n",
    "        \"IMDB-TVDB\",\n",
    "        \"TMDB-TVDB\",\n",
    "        \"Walmart-Amazon\",\n",
    "        \"Abt-Buy\",\n",
    "        \"Amazon-Google\",\n",
    "        \"DBLP-ACM\",\n",
    "        \"IMDB-TMDB\",\n",
    "        \"IMDB-TVDB\",\n",
    "        \"TMDB-TVDB\",\n",
    "        \"Walmart-Amazon\",\n",
    "        \"DBLP-Scholar\",\n",
    "        \"Abt-Buy\",\n",
    "        \"Amazon-Google\",\n",
    "        \"DBLP-ACM\",\n",
    "        \"DBLP-Scholar\",\n",
    "        \"IMDB-TMDB\",\n",
    "        \"IMDB-TVDB\",\n",
    "        \"TMDB-TVDB\",\n",
    "        \"Walmart-Amazon\",\n",
    "    ],\n",
    "    \"Model\": [\n",
    "        \"flan-t5-base\",\n",
    "        \"flan-t5-base\",\n",
    "        \"flan-t5-base\",\n",
    "        \"flan-t5-base\",\n",
    "        \"flan-t5-base\",\n",
    "        \"flan-t5-base\",\n",
    "        \"flan-t5-base\",\n",
    "        \"flan-t5-base\",\n",
    "        \"flan-t5-large\",\n",
    "        \"flan-t5-large\",\n",
    "        \"flan-t5-large\",\n",
    "        \"flan-t5-large\",\n",
    "        \"flan-t5-large\",\n",
    "        \"flan-t5-large\",\n",
    "        \"flan-t5-large\",\n",
    "        \"flan-t5-large\",\n",
    "        \"flan-t5-xl\",\n",
    "        \"flan-t5-xl\",\n",
    "        \"flan-t5-xl\",\n",
    "        \"flan-t5-xl\",\n",
    "        \"flan-t5-xl\",\n",
    "        \"flan-t5-xl\",\n",
    "        \"flan-t5-xl\",\n",
    "        \"flan-t5-xl\",\n",
    "        \"flan-t5-xxl\",\n",
    "        \"flan-t5-xxl\",\n",
    "        \"flan-t5-xxl\",\n",
    "        \"flan-t5-xxl\",\n",
    "        \"flan-t5-xxl\",\n",
    "        \"flan-t5-xxl\",\n",
    "        \"flan-t5-xxl\",\n",
    "        \"flan-t5-xxl\",\n",
    "    ],\n",
    "    \"Parameter\": [\n",
    "        250,\n",
    "        250,\n",
    "        250,\n",
    "        250,\n",
    "        250,\n",
    "        250,\n",
    "        250,\n",
    "        250,\n",
    "        780,\n",
    "        780,\n",
    "        780,\n",
    "        780,\n",
    "        780,\n",
    "        780,\n",
    "        780,\n",
    "        780,\n",
    "        3000,\n",
    "        3000,\n",
    "        3000,\n",
    "        3000,\n",
    "        3000,\n",
    "        3000,\n",
    "        3000,\n",
    "        3000,\n",
    "        11000,\n",
    "        11000,\n",
    "        11000,\n",
    "        11000,\n",
    "        11000,\n",
    "        11000,\n",
    "        11000,\n",
    "        11000,\n",
    "    ],  # Parameter size in million (M)\n",
    "    \"Precision\": [\n",
    "        60.66,\n",
    "        36.89,\n",
    "        67.44,\n",
    "        55.30,\n",
    "        82.29,\n",
    "        78.41,\n",
    "        69.17,\n",
    "        51.46,\n",
    "        62.70,\n",
    "        48.57,\n",
    "        69.44,\n",
    "        57.64,\n",
    "        92.38,\n",
    "        80.85,\n",
    "        66.18,\n",
    "        66.41,\n",
    "        69.23,\n",
    "        49.66,\n",
    "        65.56,\n",
    "        61.38,\n",
    "        89.81,\n",
    "        81.05,\n",
    "        65.22,\n",
    "        65.93,\n",
    "        71.09,\n",
    "        50.69,\n",
    "        71.94,\n",
    "        62.50,\n",
    "        89.91,\n",
    "        77.53,\n",
    "        67.91,\n",
    "        64.66,\n",
    "    ],\n",
    "    \"Recall\": [\n",
    "        74.00,\n",
    "        45.00,\n",
    "        87.00,\n",
    "        73.00,\n",
    "        79.00,\n",
    "        69.00,\n",
    "        92.00,\n",
    "        53.00,\n",
    "        71.50,\n",
    "        68.00,\n",
    "        100.00,\n",
    "        83.00,\n",
    "        97.00,\n",
    "        76.00,\n",
    "        90.00,\n",
    "        87.00,\n",
    "        90.00,\n",
    "        72.00,\n",
    "        99.00,\n",
    "        89.00,\n",
    "        97.00,\n",
    "        77.00,\n",
    "        90.00,\n",
    "        89.00,\n",
    "        91.00,\n",
    "        73.00,\n",
    "        100.00,\n",
    "        90.00,\n",
    "        98.00,\n",
    "        69.00,\n",
    "        91.00,\n",
    "        86.00,\n",
    "    ],\n",
    "    \"F1\": [\n",
    "        66.67,\n",
    "        40.54,\n",
    "        75.98,\n",
    "        62.93,\n",
    "        80.61,\n",
    "        73.40,\n",
    "        78.97,\n",
    "        52.22,\n",
    "        66.42,\n",
    "        56.67,\n",
    "        81.97,\n",
    "        68.03,\n",
    "        94.63,\n",
    "        78.35,\n",
    "        76.27,\n",
    "        75.32,\n",
    "        78.26,\n",
    "        58.78,\n",
    "        78.88,\n",
    "        72.65,\n",
    "        93.27,\n",
    "        78.97,\n",
    "        75.63,\n",
    "        75.74,\n",
    "        79.82,\n",
    "        59.84,\n",
    "        83.68,\n",
    "        73.77,\n",
    "        93.78,\n",
    "        73.02,\n",
    "        77.78,\n",
    "        73.82,\n",
    "    ],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df[\"F1\"] = df[\"F1\"]\n",
    "df[\"Precision\"] = df[\"Precision\"]\n",
    "df[\"Recall\"] = df[\"Recall\"]\n",
    "df[\"Parameter\"] = df[\"Parameter\"] / 1000\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "lineplot = sns.lineplot(\n",
    "    data=df,\n",
    "    x=\"Parameter\",\n",
    "    y=\"F1\",\n",
    "    hue=\"Dataset\",\n",
    "    style=\"Dataset\",\n",
    "    dashes=True,\n",
    "    markers=True,\n",
    ")\n",
    "lineplot.set(xlabel=\"Parameter Size (in Billions)\")\n",
    "for line in lineplot.lines:\n",
    "    line.set_markersize(8)\n",
    "plt.legend(markerscale=1.1)\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"model_size.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Model\": [\"flan-t5-base\", \"flan-t5-large\", \"flan-t5-xl\", \"flan-t5-xxl\"],\n",
    "    \"Parameter\": [250, 780, 3000, 11000],  # Parameter size in million (M)\n",
    "    \"Matching\": [57.12, 87.62, 91.50, 92.00],\n",
    "    \"Comparing\": [43.75, 63.12, 90.12, 91.38],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df[\"Parameter\"] = df[\"Parameter\"] / 1000\n",
    "df_melt = pd.melt(\n",
    "    df, id_vars=[\"Parameter\", \"Model\"], var_name=\"Strategy\", value_name=\"Recall@1\"\n",
    ")\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "lineplot = sns.lineplot(\n",
    "    data=df_melt,\n",
    "    x=\"Parameter\",\n",
    "    y=\"Recall@1\",\n",
    "    hue=\"Strategy\",\n",
    "    style=\"Strategy\",\n",
    "    dashes=True,\n",
    "    markers=True,\n",
    ")\n",
    "lineplot.set(xlabel=\"Parameter Size (in Billions)\")\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"ranking.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
